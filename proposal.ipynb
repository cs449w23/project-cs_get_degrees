{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS 449 Final Project Proposal\n",
        "\n",
        "Due: February 1, 2023 at 11:59pm\n",
        "\n",
        "## 1. Names and Net IDs\n",
        "\n",
        "Erick Mungai - mmm1176\n",
        "\n",
        "Rodney Reichert - rdr3218\n",
        "\n",
        "Perry Benyella - pbe2757\n",
        "\n",
        "## 2. Abstract\n",
        "\n",
        "Our final project seeks to use a variety of architectures to detect the presence of metastatic tissue from histopathological scans of lymph node sections. We will use both a CNN and a Residual Network(ResNet) to generate feature vectors for the images and then vary the output network between an RNN, LSTM network and a fully connected feedforward neural network. We will then compare the performance of these networks to see which performs best. The tentative combination of networks will be CNN + RNN, CNN + LSTM, CNN + feedforward neural network, ResNet + RNN, ResNet + LSTM, ResNet + feedforward neural network.\n"
      ],
      "metadata": {
        "id": "kGMAhIAC1k6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Introduction\n",
        "\n",
        "Detecting diseases in lymph nodes is crucial for effective medical diagnosis and treatment. Accurate identification of pathological changes in the lymph nodes can lead to earlier detection of diseases such as cancer leading to improved patient outcomes. This project aims to use machine learning techniques by applying different models to lymph node X-ray images to accurately detect diseases, and measure which of the model architecture we employ yields the best results. By utilizing a large dataset of high-resolution images, we can train our model to identify and classify various pathological changes in the lymph nodes."
      ],
      "metadata": {
        "id": "YX2wBFIs2S9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4a. Describe your dataset(s)\n",
        "\n",
        "We will use the PatchCamelyon (PCam) dataset, which contains a total of 327,680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. PCam is derived from the Camelyon16 Challenge, which contains 400 H&E stained WSIs of sentinel lymph node sections. The slides were acquired and digitized at 2 different centers. PCam marries the clinically-relevant task of metastasis detection into a straight-forward binary image classification task, much like MNIST. The feature structure for this dataset can be expressed through the following dictionary:\n",
        "\n",
        "    FeaturesDict({\n",
        "        'id': Text(shape=(), dtype=string),\n",
        "        'image': Image(shape=(96, 96, 3), dtype=uint8),\n",
        "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "Each datapoint has a unique id, a matrix of uint8 values representing the RGB values for each of the 96^2 pixels of the image as well as a binary label. \n",
        "\n",
        "The official website for the PatchCamelyon benchmark gives the following two references with regards to the dataset:\n",
        "\n",
        "    1. B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling. \"Rotation\n",
        "       Equivariant CNNs for Digital Pathology\". arXiv:1806.03962\n",
        "    2. Ehteshami Bejnordi et al. Diagnostic Assessment of Deep Learning       \n",
        "       Algorithms for Detection of Lymph Node Metastases in Women With Breast   \n",
        "       Cancer. JAMA: The Journal of the American Medical Association, 318(22), \n",
        "       2199–2210. doi:jama.2017.14585\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B-1Lwrn635Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 4b. Show some data\n",
        "\"\"\"\n",
        "    *Demonstrate that you have made at least some progress with getting your\n",
        "     dataset ready to use. Load at least a few examples and visualize them\n",
        "     as best you can. For example:*\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "X, y = load_digits(return_X_y=True)\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5), sharex=True,)\n",
        "plt.gray()\n",
        "for i, axis in enumerate(axes):\n",
        "    axis.matshow(X[i, :].reshape(8, 8))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "VUfetuVm5WTy",
        "outputId": "30b7a0f8-9bb8-4ad9-9376-55fed29f23dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Methods\n",
        "\n",
        "This is a binary image classification task. We will use two architectures, a CNN and a ResNet to generate feature vectors for the images. CNN are a type of neural network that is widely used for image analysis. It was popularized by AlexNet which won the 2012 ImageNet competition. Residual Networks were envisioned by Kaiming He from Microsoft Research in 2015. They use skip connections in their residual block which help in solving the vanishing gradient problem in deep CNNs. \n",
        "Since this is a standard binary classification task, we will use Binary Cross Entropy as our loss function. BCE performs best for these kinds of problems. We will use an appropriate train-validation-test split which will enable us to gauge the model’s ability to generalize to new data.\n"
      ],
      "metadata": {
        "id": "XCKtudoJ6V4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Deliverables\n",
        "\n",
        "*Include at least six goals that you think you should be able to achieve over the course of the quarter. These should be nontrivial, but you should have at least one and hopefully both of your \"Essential\" goals done by the project update, due February 24. Your \"Stretch\" goals should be ambitious enough such that completing one is doable, but completing both this quarter is unlikely.*\n",
        "\n",
        "### 6.1 Essential Goals\n",
        "- We will design a CNN and use it to generate feature vectors for the x-ray scans.\n",
        "- We will then vary the output network between an RNN, LSTM and a fully connected feedforward neural network and benchmark the performances of all of them.\n",
        "\n",
        "\n",
        "### 6.2 Desired Goals\n",
        "- Since a ResNet solves the vanishing gradient problem in deep CNNs, we will switch out the CNN for a ResNet(either design our own or use a pre-trained one) to generate the feature vectors.\n",
        "-We will then vary the output network the same way we did with the CNN and benchmark the performance.\n",
        "\n",
        "\n",
        "### 6.3 Stretch Goals\n",
        "- We will conduct a hyperparameter search for the best performing architecture combinations and see how changes in these parameters affect the performance, with the intention of improving performance even more.\n",
        "-We will test our best performing architecture on a multi-class classification task to see whether it yields the same results.\n"
      ],
      "metadata": {
        "id": "BA5eIKsR7QRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Hopes and Concerns\n",
        "\n",
        "One of the most exciting aspects of this project is the potential to contribute to the field of medical image analysis and improve disease detection in the lymph nodes. The use of advanced deep learning models such as RNNs, LSTMs, and ResNets, combined with binary classification and BCE loss, has the potential to deliver highly accurate results and make a real-world impact.\n",
        "\n",
        "One potential challenge in this project is the complexity. Working with multiple neural network architectures can lead to increased complexity in several ways. One of the main challenges is understanding the unique characteristics and limitations of each architecture and determining the best architecture for a particular problem. Additionally, each architecture may have different hyperparameters that need to be optimized for optimal performance, adding another layer of complexity to the process. Furthermore, evaluating and comparing the performance of multiple models can also be complex, as each architecture may have different strengths and weaknesses and may perform differently on different types of data. This requires a comprehensive understanding of each architecture and the ability to accurately assess their performance and compare results.\n"
      ],
      "metadata": {
        "id": "xlB_wLS381Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. References\n",
        "A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification with deep convolutional Neural Networks,” Advances in Neural Information Processing Systems, 01-Jan-1970. [Online]. Available: https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf. \n",
        "\n",
        "\n",
        "K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image Recognition,” arXiv.org, Dec. 10, 2015.[Online]. Available:  https://arxiv.org/abs/1512.03385."
      ],
      "metadata": {
        "id": "u2peFc_M8-E7"
      }
    }
  ]
}